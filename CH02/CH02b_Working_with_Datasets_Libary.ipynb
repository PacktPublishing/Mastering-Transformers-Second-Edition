{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH02b_Working_with_Datasets_Libary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY77J0ZNKU81"
      },
      "source": [
        "# CH02b_Working_with_Datasets_Libary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v642V-95KYkA"
      },
      "source": [
        "## Installing and loading a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kraPBYuum6-",
        "outputId": "00f8225e-d43d-43c3-e867-31351a98f488"
      },
      "source": [
        "!pip install datasets\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCOFA_2_1uDN"
      },
      "source": [
        "#It loads a dataset from the HuggingFace Hub\n",
        "from datasets import load_dataset"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or_Ys4yLRyB0"
      },
      "source": [
        "Datasets migth have several configurations. For instances, The GLUE dataset as an agregated benchmark has 10 subsets (as of writing this notebook) as: COLA, SST2, MRPC, QQP, STSB, MNLI, QNLI, RTE, WNLI and the diagnostic subset AX. \n",
        "\n",
        "To access each glue dataset, we pass two arguments where the first is **'glue'** and second is a **sub-part** of it to be chosen. Likewise, the wikipedia dataset have several configuration provided for several languages.\n",
        "\n",
        "Lets load 'cola' subset of GLUE as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhIhwzqgrs0D",
        "outputId": "169b419c-112b-49c5-a294-d84735dde6dc"
      },
      "source": [
        "cola = load_dataset('glue', 'cola')\n",
        "cola['train'][18:22]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': [18, 19, 20, 21],\n",
              " 'label': [0, 1, 0, 1],\n",
              " 'sentence': ['They drank the pub.',\n",
              "  'The professor talked us into a stupor.',\n",
              "  'The professor talked us.',\n",
              "  'We yelled ourselves hoarse.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRJGcaMc0dJU"
      },
      "source": [
        "While some dataset comes with DatasetDict object, some can be of type Dataset depending on splitting condition. The CoLA dataset come with DatasetDict where we have 3 splits: train,validation, and test. Train and validation datasets include the labels as well (1: Acceptable, 0: Unacceptable), but the label values of test split are -1, which means 'no-label'.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27Sie9lGwmj",
        "outputId": "d80f24cb-c0a3-44a1-bf03-edc722c2f406"
      },
      "source": [
        "cola"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['idx', 'label', 'sentence'],\n",
              "        num_rows: 8551\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['idx', 'label', 'sentence'],\n",
              "        num_rows: 1043\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['idx', 'label', 'sentence'],\n",
              "        num_rows: 1063\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_dFvOxzsz_S",
        "outputId": "d2f071c5-9a5e-4695-82ac-9c0d5f92856c"
      },
      "source": [
        "cola['train'][12]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 12, 'label': 1, 'sentence': 'Bill rolled out of the room.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24epGtdbs48Y",
        "outputId": "c466bfec-f2cc-4735-c546-e642aa4ab493"
      },
      "source": [
        "cola['validation'][68]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 68,\n",
              " 'label': 0,\n",
              " 'sentence': 'Which report that John was incompetent did he submit?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCVXKYML1Ipg",
        "outputId": "b43680c3-e9ed-4d6f-9ba9-8133aa34913b"
      },
      "source": [
        "cola['test'][20]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 20, 'label': -1, 'sentence': 'Has John seen Mary?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsirfEzWJRqb"
      },
      "source": [
        ""
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StSGBLuhJSIX"
      },
      "source": [
        "## Metadata of Datasets\n",
        "* split\n",
        "* description\n",
        "* citation\n",
        "* homepage\n",
        "* license\n",
        "* info\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4H4xeA7JTwT",
        "outputId": "8a95df66-8831-4d25-f426-2ea9e7aae191"
      },
      "source": [
        "print(cola[\"train\"].split)\n",
        "print(cola[\"train\"].description)\n",
        "print(cola[\"train\"].citation)\n",
        "print(cola[\"train\"].homepage)\n",
        "print(cola[\"train\"].license)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "GLUE, the General Language Understanding Evaluation benchmark\n",
            "(https://gluebenchmark.com/) is a collection of resources for training,\n",
            "evaluating, and analyzing natural language understanding systems.\n",
            "\n",
            "\n",
            "@article{warstadt2018neural,\n",
            "  title={Neural Network Acceptability Judgments},\n",
            "  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\n",
            "  journal={arXiv preprint arXiv:1805.12471},\n",
            "  year={2018}\n",
            "}\n",
            "@inproceedings{wang2019glue,\n",
            "  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
            "  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
            "  note={In the Proceedings of ICLR.},\n",
            "  year={2019}\n",
            "}\n",
            "\n",
            "https://nyu-mll.github.io/CoLA/\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wce0ixTa1IBW"
      },
      "source": [
        "### Loading other datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnshcHTRs4_K",
        "outputId": "a09a5f10-4f3e-49fe-8be8-66e0e5dc1875"
      },
      "source": [
        "sst2 = load_dataset('glue', 'sst2')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt0IsbSys5Bn",
        "outputId": "e37d70f1-1ba3-4b5a-b3a7-b36e8b4a1bc9"
      },
      "source": [
        "mrpc = load_dataset('glue', 'mrpc')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X3n64WwL2Pt"
      },
      "source": [
        "To check entire subsets, run the following piece of code\n",
        "\n",
        "\n",
        "```\n",
        "glue=['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']\n",
        "for g in glue:\n",
        " _=load_dataset('glue', g)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfUequG1r3rT"
      },
      "source": [
        ""
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY8ytQiLMKG5"
      },
      "source": [
        "## Listing all datasets and metrics in the hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwUjI5XysDjh",
        "outputId": "3899bdca-4197-452b-f164-633f382ed892"
      },
      "source": [
        "from pprint import pprint\n",
        "from datasets import list_datasets, list_metrics\n",
        "all = list_datasets()\n",
        "metrics = list_metrics()\n",
        "\n",
        "print(f\"{len(all)} datasets and {len(metrics)} metrics exists in the hub\\n\")\n",
        "pprint(all[:20], compact=True)\n",
        "pprint(metrics, compact=True)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "995 datasets and 27 metrics exists in the hub\n",
            "\n",
            "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc',\n",
            " 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue',\n",
            " 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity',\n",
            " 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'amttl', 'anli',\n",
            " 'app_reviews', 'aqua_rat']\n",
            "['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'comet', 'coval', 'cuad',\n",
            " 'f1', 'gleu', 'glue', 'indic_glue', 'matthews_correlation', 'meteor',\n",
            " 'pearsonr', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval',\n",
            " 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'wer', 'xnli']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGbsj2zLMOMR"
      },
      "source": [
        "## XTREME: Working with Cross-lingual dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADiPVFG4ANK"
      },
      "source": [
        "MLQA is a subset of Xtreme benchmark, which is designed for assessing performances of cross-lingual question answering models. It includes about 5K extractive Question-Answer instances in SQuAD format in seven languages which are:\n",
        "* (English, German, Arabic, Hindi, Vietnamese, Spanish and Simplified Chinese.) \n",
        "\n",
        "E.g. MLQA.en.de is English-German QA example dataset and can be loaded as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxo2P4yNCnlz",
        "outputId": "b66fd420-f6d9-4efc-d847-c466cad8d8cc"
      },
      "source": [
        "en_de = load_dataset('xtreme', 'MLQA.en.de')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset xtreme (/root/.cache/huggingface/datasets/xtreme/MLQA.en.de/1.0.0/7bf67e71297af51aebad531f84e824cf5c995d9ce994485f7cd2e90d9cc4d555)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3VekHNKGtBg"
      },
      "source": [
        ""
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUn-BxLfX1P5"
      },
      "source": [
        "Here is the dataset structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Dqp9hR1Yfm",
        "outputId": "72654923-80c5-4f06-fc50-37d5dd86466b"
      },
      "source": [
        "en_de"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
              "        num_rows: 4517\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
              "        num_rows: 512\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyKgKcdR3jVi"
      },
      "source": [
        "### Viewing the dataset as a pandas data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "0Ilhb2j71fiC",
        "outputId": "e85d4d6c-fafb-4dc2-fe23-6ef3322a1e46"
      },
      "source": [
        "# View dataset as a pandas data frame\n",
        "import pandas as pd\n",
        "pd.DataFrame(en_de['test'][0:4])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'answer_start': [31], 'text': ['cell']}</td>\n",
              "      <td>An established or immortalized cell line has a...</td>\n",
              "      <td>037e8929e7e4d2f949ffbabd10f0f860499ff7c9</td>\n",
              "      <td>Woraus besteht die Linie?</td>\n",
              "      <td>Cell culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'answer_start': [232], 'text': ['1885']}</td>\n",
              "      <td>The 19th-century English physiologist Sydney R...</td>\n",
              "      <td>4b36724f3cbde7c287bde512ff09194cbba7f932</td>\n",
              "      <td>Wann hat Roux etwas von seiner Medullarplatte ...</td>\n",
              "      <td>Cell culture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'answer_start': [131], 'text': ['TRIPS']}</td>\n",
              "      <td>After the Uruguay round, the GATT became the b...</td>\n",
              "      <td>13e58403df16d88b0e2c665953e89575704942d4</td>\n",
              "      <td>Was muss ratifiziert werden, wenn ein Land ger...</td>\n",
              "      <td>TRIPS Agreement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'answer_start': [67], 'text': ['developing co...</td>\n",
              "      <td>Since TRIPS came into force, it has been subje...</td>\n",
              "      <td>d23b5372af1de9425a4ae313c01eb80764c910d8</td>\n",
              "      <td>Welche Teile der Welt kritisierten das TRIPS a...</td>\n",
              "      <td>TRIPS Agreement</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             answers  ...            title\n",
              "0           {'answer_start': [31], 'text': ['cell']}  ...     Cell culture\n",
              "1          {'answer_start': [232], 'text': ['1885']}  ...     Cell culture\n",
              "2         {'answer_start': [131], 'text': ['TRIPS']}  ...  TRIPS Agreement\n",
              "3  {'answer_start': [67], 'text': ['developing co...  ...  TRIPS Agreement\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YullrhmI5lHO"
      },
      "source": [
        "## Selecting, sorting, filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azBvXH8F3uYk"
      },
      "source": [
        "### Split\n",
        "which split of the data to be loaded. If None by default, will return a `dict` with all splits (Train, Test, Validation or any other).  If split is specified, it will return a single Dataset rather than a Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gyi_LgUPVtq",
        "outputId": "17d7fae8-8807-4596-d063-dd36e0798d63"
      },
      "source": [
        "cola = load_dataset('glue', 'cola', split ='train[:300]+validation[-30%:]')\n",
        "# Which means the first 300 examples of train  plus the last 30% of validation."
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnncU49m4V9q"
      },
      "source": [
        "#### Other Split Examples\n",
        "The first 100 examples from train and validation\n",
        "\n",
        "`split='train[:100]+validation[:100]'` \n",
        "\n",
        "50% of train and 30 % of validation\n",
        "\n",
        "`split='train[:50%]+validation[:30%]'`\n",
        "\n",
        "\n",
        "The first 20% of train and examples in the slice 30:50 from validation\n",
        "\n",
        "`split='train[:20%]+validation[30:50]'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4x7vJIh-697"
      },
      "source": [
        "### Sorting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57MIyMY0_PWq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZMNeQfe-7Uw",
        "outputId": "940c9d5a-4483-4e80-9f3e-d6789dfadc32"
      },
      "source": [
        "cola.sort('label')['label'][:15]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached sorted indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-54fbf680867c6dca.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvUxINYb_BWH",
        "outputId": "e043ce46-b054-4d5c-8b90-7956bb2802bd"
      },
      "source": [
        "cola.sort('label')['label'][-15:]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached sorted indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-54fbf680867c6dca.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-VVYvtU_Qku"
      },
      "source": [
        ""
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DZ7T9-h_R5O"
      },
      "source": [
        "###  Indexing\n",
        "You can also access several rows using slice notation or with a list of indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukx2v_b6AHW1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoqiXsjf_yBV",
        "outputId": "e6c9762b-3e9f-4adb-f197-3c3d7c2aa6b2"
      },
      "source": [
        "cola[6,19,44]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': [6, 19, 44],\n",
              " 'label': [1, 1, 1],\n",
              " 'sentence': ['Fred watered the plants flat.',\n",
              "  'The professor talked us into a stupor.',\n",
              "  'The trolley rumbled through the tunnel.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eAbIIMR_6CW",
        "outputId": "f7ee506a-b937-4737-892d-0d9dfd6425f3"
      },
      "source": [
        "cola[42:46]"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': [42, 43, 44, 45],\n",
              " 'label': [0, 1, 1, 1],\n",
              " 'sentence': ['They made him to exhaustion.',\n",
              "  'They made him into a monster.',\n",
              "  'The trolley rumbled through the tunnel.',\n",
              "  'The wagon rumbled down the road.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kouidG0PAIg2"
      },
      "source": [
        "### Shuffling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OQ8DLJcAKv4",
        "outputId": "e6047b2f-0c39-4aa4-89a8-8d42a6ad1c71"
      },
      "source": [
        "cola.shuffle(seed=42)[:3]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97a24a7d09391f14.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': [904, 1017, 885],\n",
              " 'label': [1, 0, 1],\n",
              " 'sentence': ['Lou forgot the umbrella in the closet.',\n",
              "  'It is the problem that he is here.',\n",
              "  'I met the person who left.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5atyj-_59tJ"
      },
      "source": [
        "## Caching and reusability\n",
        "Using cache files allows us to load large datasets by means of memory mapping if datasets fit on the drive  to use a fast backend and do smart caching by saving and reusing the results of operations executed on the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT79Q8hz_5i3"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KmKHVN4cRY3"
      },
      "source": [
        ""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlKPEB2RccN7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xdxVno0Pguy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc962d64-4335-4a06-e1f6-b355263527ca"
      },
      "source": [
        "pprint(list(dir(cola)))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__class__',\n",
            " '__del__',\n",
            " '__delattr__',\n",
            " '__dict__',\n",
            " '__dir__',\n",
            " '__doc__',\n",
            " '__enter__',\n",
            " '__eq__',\n",
            " '__exit__',\n",
            " '__format__',\n",
            " '__ge__',\n",
            " '__getattribute__',\n",
            " '__getitem__',\n",
            " '__gt__',\n",
            " '__hash__',\n",
            " '__init__',\n",
            " '__init_subclass__',\n",
            " '__iter__',\n",
            " '__le__',\n",
            " '__len__',\n",
            " '__lt__',\n",
            " '__module__',\n",
            " '__ne__',\n",
            " '__new__',\n",
            " '__reduce__',\n",
            " '__reduce_ex__',\n",
            " '__repr__',\n",
            " '__setattr__',\n",
            " '__sizeof__',\n",
            " '__slotnames__',\n",
            " '__str__',\n",
            " '__subclasshook__',\n",
            " '__weakref__',\n",
            " '_check_index_is_initialized',\n",
            " '_data',\n",
            " '_fingerprint',\n",
            " '_format_columns',\n",
            " '_format_kwargs',\n",
            " '_format_type',\n",
            " '_get_cache_file_path',\n",
            " '_getitem',\n",
            " '_indexes',\n",
            " '_indices',\n",
            " '_info',\n",
            " '_map_single',\n",
            " '_new_dataset_with_indices',\n",
            " '_output_all_columns',\n",
            " '_split',\n",
            " 'add_column',\n",
            " 'add_elasticsearch_index',\n",
            " 'add_faiss_index',\n",
            " 'add_faiss_index_from_external_arrays',\n",
            " 'add_item',\n",
            " 'builder_name',\n",
            " 'cache_files',\n",
            " 'cast',\n",
            " 'cast_',\n",
            " 'citation',\n",
            " 'class_encode_column',\n",
            " 'cleanup_cache_files',\n",
            " 'column_names',\n",
            " 'config_name',\n",
            " 'data',\n",
            " 'dataset_size',\n",
            " 'description',\n",
            " 'dictionary_encode_column_',\n",
            " 'download_checksums',\n",
            " 'download_size',\n",
            " 'drop_index',\n",
            " 'export',\n",
            " 'features',\n",
            " 'filter',\n",
            " 'flatten',\n",
            " 'flatten_',\n",
            " 'flatten_indices',\n",
            " 'format',\n",
            " 'formatted_as',\n",
            " 'from_buffer',\n",
            " 'from_csv',\n",
            " 'from_dict',\n",
            " 'from_file',\n",
            " 'from_json',\n",
            " 'from_pandas',\n",
            " 'from_text',\n",
            " 'get_index',\n",
            " 'get_nearest_examples',\n",
            " 'get_nearest_examples_batch',\n",
            " 'homepage',\n",
            " 'info',\n",
            " 'is_index_initialized',\n",
            " 'license',\n",
            " 'list_indexes',\n",
            " 'load_elasticsearch_index',\n",
            " 'load_faiss_index',\n",
            " 'load_from_disk',\n",
            " 'map',\n",
            " 'num_columns',\n",
            " 'num_rows',\n",
            " 'prepare_for_task',\n",
            " 'remove_columns',\n",
            " 'remove_columns_',\n",
            " 'rename_column',\n",
            " 'rename_column_',\n",
            " 'rename_columns',\n",
            " 'reset_format',\n",
            " 'save_faiss_index',\n",
            " 'save_to_disk',\n",
            " 'search',\n",
            " 'search_batch',\n",
            " 'select',\n",
            " 'set_format',\n",
            " 'set_transform',\n",
            " 'shape',\n",
            " 'shard',\n",
            " 'shuffle',\n",
            " 'size_in_bytes',\n",
            " 'sort',\n",
            " 'split',\n",
            " 'supervised_keys',\n",
            " 'to_csv',\n",
            " 'to_dict',\n",
            " 'to_json',\n",
            " 'to_pandas',\n",
            " 'train_test_split',\n",
            " 'unique',\n",
            " 'version',\n",
            " 'with_format',\n",
            " 'with_transform']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKjoobg7yy4",
        "outputId": "9540b76d-eed6-496b-da59-71d2bce66b48"
      },
      "source": [
        "cola.cache_files"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'filename': '/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue-train.arrow'},\n",
              " {'filename': '/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue-validation.arrow'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN7OLqp97Mdx",
        "outputId": "265bd75e-c97e-4572-a65d-51b7ecfdb6ca"
      },
      "source": [
        "cola.info"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetInfo(description='GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n', citation='@article{warstadt2018neural,\\n  title={Neural Network Acceptability Judgments},\\n  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},\\n  journal={arXiv preprint arXiv:1805.12471},\\n  year={2018}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n', homepage='https://nyu-mll.github.io/CoLA/', license='', features={'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['unacceptable', 'acceptable'], names_file=None, id=None), 'sentence': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='glue', config_name='cola', version=1.0.0, splits={'train': SplitInfo(name='train', num_bytes=484873, num_examples=8551, dataset_name='glue'), 'validation': SplitInfo(name='validation', num_bytes=60326, num_examples=1043, dataset_name='glue'), 'test': SplitInfo(name='test', num_bytes=60517, num_examples=1063, dataset_name='glue')}, download_checksums={'https://dl.fbaipublicfiles.com/glue/data/CoLA.zip': {'num_bytes': 376971, 'checksum': 'f212fcd832b8f7b435fb991f101abf89f96b933ab400603bf198960dfc32cbff'}}, download_size=376971, post_processing_size=None, dataset_size=605716, size_in_bytes=982687)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVXL4bJ1BUJ1"
      },
      "source": [
        "## Dataset Filter and Map Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkGts_39ISL"
      },
      "source": [
        "### Filter function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gthxqxRfG_wc",
        "outputId": "1ce5f4af-0c71-4931-e3ab-2be3bd342ec9"
      },
      "source": [
        "# To get 3 sentences ,including the term \"kick\" with Filter\n",
        "cola = load_dataset('glue', 'cola', split='train[:100%]+validation[-30%:]')\n",
        "pprint(cola.filter(lambda s: \"kick\" in s['sentence'])[\"sentence\"][:3])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9893a54d32e436a9.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Jill kicked the ball from home plate to third base.',\n",
            " 'Fred kicked the ball under the porch.',\n",
            " 'Fred kicked the ball behind the tree.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QHMyXqVHsrt",
        "outputId": "7ddcd3bb-a4ba-4b00-c162-1cd3bbc5aa02"
      },
      "source": [
        "# To get 3 acceptable sentences\n",
        "pprint(cola.filter(lambda s: s['label']== 1 )[\"sentence\"][:3])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f5b5fbadebcc9c76.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
            " \"One more pseudo generalization and I'm giving up.\",\n",
            " \"One more pseudo generalization or I'm giving up.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXkjxZwnIu1o",
        "outputId": "a43edbf3-f224-4f68-fa0e-c44b2a03c413"
      },
      "source": [
        "# To get 3 acceptable sentences - alternative version\n",
        "cola.filter(lambda s: s['label']== cola.features['label'].str2int('acceptable'))[\"sentence\"][:3]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6665684662c122c0.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
              " \"One more pseudo generalization and I'm giving up.\",\n",
              " \"One more pseudo generalization or I'm giving up.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuxdPIGhRRp6"
      },
      "source": [
        "### Processing data with  map function\n",
        "datasets.Dataset.map() function iterates over the dataset applying a processing function to each examples in a dataset and modifies the content of the samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7hEPB9gJzcO",
        "outputId": "6917d96f-ea6e-4c5a-eeda-5389312d1c9e"
      },
      "source": [
        "# E.g. adding new features\n",
        "cola_new=cola.map(lambda e: {'len': len(e['sentence'])})"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-624419b59807378b.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzIzv3SCr4F",
        "outputId": "9d1317a7-319e-465d-8d68-1f1de2a79fbc"
      },
      "source": [
        "cola_new"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['idx', 'label', 'len', 'sentence'],\n",
              "    num_rows: 8864\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6yZbdB3Kiyk",
        "outputId": "87075ea6-bed1-4342-c3be-265b515dc27b"
      },
      "source": [
        "pprint(cola_new[0:3])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'idx': [0, 1, 2],\n",
            " 'label': [1, 1, 1],\n",
            " 'len': [71, 49, 48],\n",
            " 'sentence': [\"Our friends won't buy this analysis, let alone the next one we \"\n",
            "              'propose.',\n",
            "              \"One more pseudo generalization and I'm giving up.\",\n",
            "              \"One more pseudo generalization or I'm giving up.\"]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV8FUZqZKxu4",
        "outputId": "796afadd-abea-498a-eb18-944e05c4708d"
      },
      "source": [
        "cola_cut=cola_new.map(lambda e: {'sentence': e['sentence'][:20]})"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-497438506d3d554b.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZZ7N7tXLdU3",
        "outputId": "3561afc4-31d6-4206-e242-03e210ec7fcd"
      },
      "source": [
        "pprint(cola_cut[:3])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'idx': [0, 1, 2],\n",
            " 'label': [1, 1, 1],\n",
            " 'len': [71, 49, 48],\n",
            " 'sentence': [\"Our friends won't bu\",\n",
            "              'One more pseudo gene',\n",
            "              'One more pseudo gene']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYOl0pumR4Sa"
      },
      "source": [
        ""
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO1yD63jR_oX"
      },
      "source": [
        "## Working with Local Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATU9RvvRUj3t",
        "outputId": "691082ab-f89b-400e-8b4b-c4f7a57976de"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1-Psk5XmYiG4",
        "outputId": "e06a96e6-c72a-43ab-aad1-0d95f3a6f877"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13plSMLLYs4m",
        "outputId": "81d63d95-35ac-4744-e381-cc3079e3879b"
      },
      "source": [
        "os.listdir(\"/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CH02b_Working_with_Datasets_Libary.ipynb',\n",
              " 'data',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers.mp4',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers .ipynb',\n",
              " 'CH02c_Speed_and_Memory_Benchmarking.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsAmx8r5U5WC"
      },
      "source": [
        "if os.getcwd()!='/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02':\n",
        "    os.chdir(\"drive/MyDrive/akademi/Packt NLP with Transformers/CH02\")"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_lj0qbmrY6jo",
        "outputId": "3e9bbfcf-cc27-4706-ca9c-6c441fa24612"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/akademi/Packt NLP with Transformers/CH02'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkJmZzW-ViHZ",
        "outputId": "5e706836-4543-45d3-97df-94c34b1238cb"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CH02b_Working_with_Datasets_Libary.ipynb',\n",
              " 'data',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers.mp4',\n",
              " 'CH02a_Working_with_Language_Models_and_Tokenizers .ipynb',\n",
              " 'CH02c_Speed_and_Memory_Benchmarking.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoBmadKXSDSS"
      },
      "source": [
        "# To load a dataset from local files CSV, TXT, JSON, a generic loading scripts are provided "
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_d1XDESVDT",
        "outputId": "0c6ee4c3-4059-4e02-8aa7-ea18822c73ca"
      },
      "source": [
        "# under data folder there are the files[a.csv, b.csv, c.csv], some random part of SST-2 dataset\n",
        "from datasets import load_dataset\n",
        "data1 = load_dataset('csv', data_files='./data/a.csv', delimiter=\"\\t\")\n",
        "data2 = load_dataset('csv', data_files=['./data/a.csv','./data/b.csv', './data/c.csv'], delimiter=\"\\t\")\n",
        "data3 = load_dataset('csv', data_files={'train':['./data/a.csv','./data/b.csv'], 'test':['./data/c.csv']}, delimiter=\"\\t\") "
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-811df5c9519fddd3\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-811df5c9519fddd3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
            "Using custom data configuration default-37a89142f75f1c5a\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-37a89142f75f1c5a/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
            "Using custom data configuration default-6468b1b0b5900944\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ZeHJzioJTNt3",
        "outputId": "13187cd2-8d64-4b87-91ee-1e94e58c5a72"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(data1[\"train\"][:3])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that loves its characters and communicates som...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0       hide new secretions from the parental units       0\n",
              "1               contains no wit , only labored gags       0\n",
              "2  that loves its characters and communicates som...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "b2utSTp7WYIj",
        "outputId": "35679bca-2640-4239-f7bd-e86cd2e476fd"
      },
      "source": [
        "pd.DataFrame(data3[\"test\"][:3])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>inane and awful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>told in scattered fashion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>takes chances that are bold by studio standards</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                          sentence\n",
              "0      0                                  inane and awful \n",
              "1      0                        told in scattered fashion \n",
              "2      1  takes chances that are bold by studio standards "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgSL1tJDZtUb"
      },
      "source": [
        "# get the files in other format\n",
        "# data_json = load_dataset('json', data_files='a.json')\n",
        "# data_text = load_dataset('text', data_files='a.txt')\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrhYk5RZcw_9"
      },
      "source": [
        "#you can also access several rows using slice notation or with a list of indices"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxR0MF2HCT0"
      },
      "source": [
        "# shuffling"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE3xOlHagXsC",
        "outputId": "45394197-8d4a-4d36-ff2e-0663487e5a6b"
      },
      "source": [
        "data3_shuf=data3['train'].shuffle(seed=42)\n",
        "data3_shuf['label'][:15]\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-3a29ecf37f77eb59.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GgSENedtivK"
      },
      "source": [
        "\n"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzvvWYc_tjld"
      },
      "source": [
        "## Preparing the data for model training\n",
        "Let us take an example with a tokenizer. \n",
        "To do so, we need to install transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2-XEKRHtvUM",
        "outputId": "61e65f3b-1153-4da5-e15a-02bb32240569"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD0r-dcItb3D"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leJcuyuHtdmh"
      },
      "source": [
        ""
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBfqdGSGBRKj"
      },
      "source": [
        "If batched is True, it provides batch of examples to any function.\n",
        "batch_size (default is 1000) is  number of instances per batch provided to a function. If not selected, the whole dataset is provided as a single batch to any given function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MckfxQQB1ljN",
        "outputId": "b5c27f2e-e0e6-44a4-bc33-7f55767a28fe"
      },
      "source": [
        "encoded_data1 = data1.map( lambda e: tokenizer(e['sentence']), batched=True, batch_size=1000)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-811df5c9519fddd3/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-c17d30f249048b0c.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfUEGoo3IMpt",
        "outputId": "0f0e56a7-fd9f-4c7a-85e4-91adeec428c4"
      },
      "source": [
        "data1"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 99\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5SbL4tU1qVo",
        "outputId": "6f1bfe4e-3272-4e7d-ece3-1ed5e0aa0dde"
      },
      "source": [
        "encoded_data1"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['attention_mask', 'input_ids', 'label', 'sentence'],\n",
              "        num_rows: 99\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XlrYuBiuPEH",
        "outputId": "414bb20b-13f1-4cd0-bdab-6d83ed1bc9d4"
      },
      "source": [
        "pprint(encoded_data1['train'][0])"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            " 'input_ids': [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
            " 'label': 0,\n",
            " 'sentence': 'hide new secretions from the parental units '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfZI9p-yuRmQ"
      },
      "source": [
        ""
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdvjGHWUzZlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c5dbd2-7681-4858-d21e-bd32613148b0"
      },
      "source": [
        "encoded_data3 = data3.map(lambda e: tokenizer( e['sentence'], padding=True, truncation=True, max_length=12), batched=True, batch_size=1000) "
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-d1d250b2127835bc.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6468b1b0b5900944/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-99b6e3afa67cadc0.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-OQEKTKeUmJ",
        "outputId": "15a2204e-ca64-4102-a2da-001ba36f81eb"
      },
      "source": [
        "data3"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 199\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'sentence'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCY68Toieb69",
        "outputId": "5608c181-be6a-4247-bb44-cee557fb71d1"
      },
      "source": [
        "encoded_data3"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['attention_mask', 'input_ids', 'label', 'sentence'],\n",
              "        num_rows: 199\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['attention_mask', 'input_ids', 'label', 'sentence'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPgYyTebeey4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce084847-0172-48fa-ded0-9b902b80f6bf"
      },
      "source": [
        "pprint(encoded_data3['test'][12])"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            " 'input_ids': [101, 2019, 5186, 16010, 2143, 1012, 102, 0, 0, 0, 0, 0],\n",
            " 'label': 0,\n",
            " 'sentence': 'an extremely unpleasant film . '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWekEQLreigN"
      },
      "source": [
        ""
      ],
      "execution_count": 170,
      "outputs": []
    }
  ]
}