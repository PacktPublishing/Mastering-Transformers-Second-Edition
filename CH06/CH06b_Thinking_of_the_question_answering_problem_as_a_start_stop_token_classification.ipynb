{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CH06b_Thinking_of_the_question_answering_problem_as_a_start_stop_token_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqbtDoeS62EdaB9izLFGQS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"915a1f6cf7dc44ec8220c5a15c9621fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a375090589e34ff79bece2aa40b96d3d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_281534e394b64fad93d6b0fff70ffaba","IPY_MODEL_7a71680305f84a748f5be2dd55f1b100"]}},"a375090589e34ff79bece2aa40b96d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"281534e394b64fad93d6b0fff70ffaba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_facb81b5518445ad9ee2f6a6cc98e6e5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":12,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":12,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_895462cff46b4dd8b5e3379e41c737fc"}},"7a71680305f84a748f5be2dd55f1b100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d50943b2ba114b8fa6d7e902057613db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 12/12 [00:08&lt;00:00,  1.37ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3728b6af2be24530891961dde3d28b1b"}},"facb81b5518445ad9ee2f6a6cc98e6e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"895462cff46b4dd8b5e3379e41c737fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d50943b2ba114b8fa6d7e902057613db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3728b6af2be24530891961dde3d28b1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"4U0BzgMnggOa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335697708,"user_tz":-180,"elapsed":3051,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"397238d3-95eb-435b-bf75-374b1d62e253"},"source":["!pip install transformers datasets tokenizers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EoB07OSUgkJR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335702172,"user_tz":-180,"elapsed":1261,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"80ff9b93-a218-4f33-e9c7-505a2fd5c71a"},"source":["from pprint import pprint \n","from datasets import load_dataset \n","squad = load_dataset(\"squad\") \n","for item in squad[\"train\"][1].items(): \n","    print(item[0]) \n","    pprint(item[1]) \n","    print(\"=\"*20) "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16)\n"],"name":"stderr"},{"output_type":"stream","text":["answers\n","{'answer_start': [188], 'text': ['a copper statue of Christ']}\n","====================\n","context\n","('Architecturally, the school has a Catholic character. Atop the Main '\n"," \"Building's gold dome is a golden statue of the Virgin Mary. Immediately in \"\n"," 'front of the Main Building and facing it, is a copper statue of Christ with '\n"," 'arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main '\n"," 'Building is the Basilica of the Sacred Heart. Immediately behind the '\n"," 'basilica is the Grotto, a Marian place of prayer and reflection. It is a '\n"," 'replica of the grotto at Lourdes, France where the Virgin Mary reputedly '\n"," 'appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive '\n"," '(and in a direct line that connects through 3 statues and the Gold Dome), is '\n"," 'a simple, modern stone statue of Mary.')\n","====================\n","id\n","'5733be284776f4190066117f'\n","====================\n","question\n","'What is in front of the Notre Dame Main Building?'\n","====================\n","title\n","'University_of_Notre_Dame'\n","====================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qB1wQbsojQok","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335705487,"user_tz":-180,"elapsed":444,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"42248809-be40-4361-deb5-9ee3cea741b2"},"source":["from datasets import load_dataset \n","squad = load_dataset(\"squad_v2\") "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/de2e67b822b2ef3f4b137148d0758f48075e3892c359c50271ef6c9add7e794a)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gE0ft2p6jYRb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335707865,"user_tz":-180,"elapsed":292,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"d4d07397-b45e-4654-8b13-96adcf65686b"},"source":["squad"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['answers', 'context', 'id', 'question', 'title'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['answers', 'context', 'id', 'question', 'title'],\n","        num_rows: 11873\n","    })\n","})"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"x6NIZCe1jb4k","executionInfo":{"status":"ok","timestamp":1625335710571,"user_tz":-180,"elapsed":720,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["from transformers import AutoTokenizer \n","model = \"distilbert-base-uncased\" \n","tokenizer = AutoTokenizer.from_pretrained(model) "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvnumMYfjfPz","executionInfo":{"status":"ok","timestamp":1625335712734,"user_tz":-180,"elapsed":305,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["max_length = 384 \n","doc_stride = 128 \n","example = squad[\"train\"][173] \n","tokenized_example = tokenizer( \n","example[\"question\"], \n","example[\"context\"], \n","max_length=max_length, \n","truncation=\"only_second\", \n","return_overflowing_tokens=True, \n","stride=doc_stride \n",") "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqaQURlQjhu6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335714901,"user_tz":-180,"elapsed":289,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"8fd73f47-8add-491f-d64d-aa2421fa9201"},"source":["len(tokenized_example['input_ids'])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"IrHSIJFbjm_U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335717855,"user_tz":-180,"elapsed":1702,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"954ebce5-6632-4764-8310-6c6bb4614be2"},"source":["for input_ids in tokenized_example[\"input_ids\"][:2]: \n","    print(tokenizer.decode(input_ids)) \n","    print(\"-\"*50) "],"execution_count":8,"outputs":[{"output_type":"stream","text":["[CLS] beyonce got married in 2008 to whom? [SEP] on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five songs \" if i were a boy \" and \" halo \". achieving the accomplishment of becoming her longest - running hot 100 single in her career, \" halo \"'s success in the us helped beyonce attain more top - ten singles on the list than any other woman during the 2000s. it also included the successful \" sweet dreams \", and singles \" diva \", \" ego \", \" broken - hearted girl \" and \" video phone \". the music video for \" single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce [SEP]\n","--------------------------------------------------\n","[CLS] beyonce got married in 2008 to whom? [SEP] single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce improvising a re - presentation of swift's award during her own acceptance speech. in march 2009, beyonce embarked on the i am... world tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $ 119. 5 million. [SEP]\n","--------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmroNAfojppS","executionInfo":{"status":"ok","timestamp":1625335727599,"user_tz":-180,"elapsed":395,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["def prepare_train_features(examples, pad_on_right=True): \n","    tokenized_examples = tokenizer( \n","        examples[\"question\" if pad_on_right else \"context\"], \n","        examples[\"context\" if pad_on_right else \"question\"], \n","        truncation=\"only_second\" if pad_on_right else \"only_first\", \n","        max_length=max_length, \n","        stride=doc_stride, \n","        return_overflowing_tokens=True, \n","        return_offsets_mapping=True, \n","        padding=\"max_length\", \n","    ) \n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\") \n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\") \n","    tokenized_examples[\"start_positions\"] = [] \n","    tokenized_examples[\"end_positions\"] = [] \n","    for i, offsets in enumerate(offset_mapping): \n","        input_ids = tokenized_examples[\"input_ids\"][i] \n","        cls_index = input_ids.index(tokenizer.cls_token_id) \n","        sequence_ids = tokenized_examples.sequence_ids(i) \n","        sample_index = sample_mapping[i] \n","        answers = examples[\"answers\"][sample_index] \n","        if len(answers[\"answer_start\"]) == 0: \n","            tokenized_examples[\"start_positions\"].append(cls_index) \n","            tokenized_examples[\"end_positions\"].append(cls_index) \n","        else: \n","            start_char = answers[\"answer_start\"][0] \n","            end_char = start_char + len(answers[\"text\"][0]) \n","            token_start_index = 0 \n","            while sequence_ids[token_start_index] != (1 if pad_on_right else 0): \n","                token_start_index += 1 \n","            token_end_index = len(input_ids) - 1 \n","            while sequence_ids[token_end_index] != (1 if pad_on_right else 0): \n","                token_end_index -= 1 \n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char): \n","                tokenized_examples[\"start_positions\"].append(cls_index) \n","                tokenized_examples[\"end_positions\"].append(cls_index) \n","            else: \n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char: \n","                    token_start_index += 1 \n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1) \n","                while offsets[token_end_index][1] >= end_char: \n","                    token_end_index -= 1 \n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1) \n","    return tokenized_examples "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"13isfE-pj2hQ","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["915a1f6cf7dc44ec8220c5a15c9621fe","a375090589e34ff79bece2aa40b96d3d","281534e394b64fad93d6b0fff70ffaba","7a71680305f84a748f5be2dd55f1b100","facb81b5518445ad9ee2f6a6cc98e6e5","895462cff46b4dd8b5e3379e41c737fc","d50943b2ba114b8fa6d7e902057613db","3728b6af2be24530891961dde3d28b1b"]},"executionInfo":{"status":"ok","timestamp":1625335735501,"user_tz":-180,"elapsed":6099,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"e079e098-f78b-4e10-d878-a53725e7bd44"},"source":["tokenized_datasets = squad.map(prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/de2e67b822b2ef3f4b137148d0758f48075e3892c359c50271ef6c9add7e794a/cache-9d22a5ad1f8439e2.arrow\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"915a1f6cf7dc44ec8220c5a15c9621fe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ONDxm04Pj4_5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335739138,"user_tz":-180,"elapsed":1376,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"2c11701d-7e2e-4c4d-c607-0644491403b7"},"source":["from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer \n","model = AutoModelForQuestionAnswering.from_pretrained(model) "],"execution_count":11,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8k3Dh6LTkH5X","executionInfo":{"status":"ok","timestamp":1625335742102,"user_tz":-180,"elapsed":275,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["args = TrainingArguments( \n","f\"test-squad\", \n","evaluation_strategy = \"epoch\", \n","learning_rate=2e-5, \n","per_device_train_batch_size=16, \n","per_device_eval_batch_size=16, \n","num_train_epochs=3, \n","weight_decay=0.01, \n",")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5XA1jW5kMIZ","executionInfo":{"status":"ok","timestamp":1625335744587,"user_tz":-180,"elapsed":283,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["from transformers import default_data_collator \n","data_collator = default_data_collator "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHjOTzEbkOaQ","executionInfo":{"status":"ok","timestamp":1625335749397,"user_tz":-180,"elapsed":3679,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}}},"source":["trainer = Trainer( \n","model, \n","args, \n","train_dataset=tokenized_datasets[\"train\"], \n","eval_dataset=tokenized_datasets[\"validation\"], \n","data_collator=data_collator, \n","tokenizer=tokenizer, \n",") "],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHLycxXbkRug","colab":{"base_uri":"https://localhost:8080/","height":514},"executionInfo":{"status":"error","timestamp":1625335777154,"user_tz":-180,"elapsed":26031,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"0051da83-c9d5-4efd-cd48-dc0c4a8ed1b9"},"source":["trainer.train() "],"execution_count":15,"outputs":[{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 131754\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 24705\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='46' max='24705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   46/24705 00:23 < 3:42:06, 1.85 it/s, Epoch 0.01/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-2a4521c5cd87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"9cULETzEkTlm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335784727,"user_tz":-180,"elapsed":763,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"edfa5db5-4031-44b3-cc8a-3ad5a471160a"},"source":["trainer.save_model(\"distillBERT_SQUAD\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Saving model checkpoint to distillBERT_SQUAD\n","Configuration saved in distillBERT_SQUAD/config.json\n","Model weights saved in distillBERT_SQUAD/pytorch_model.bin\n","tokenizer config file saved in distillBERT_SQUAD/tokenizer_config.json\n","Special tokens file saved in distillBERT_SQUAD/special_tokens_map.json\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MZJSPSQokV1_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335789126,"user_tz":-180,"elapsed":1724,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"4bc3cd6e-a2dc-47de-981b-b0d369ec2771"},"source":["from transformers import pipeline \n","qa_model = pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='distilbert-base-cased') "],"execution_count":17,"outputs":[{"output_type":"stream","text":["loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": true,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.8.2\",\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForQuestionAnswering\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": true,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.8.2\",\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n","All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n","\n","All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n","loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.8.2\",\n","  \"vocab_size\": 28996\n","}\n","\n","loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Ln992fI2kYMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335794978,"user_tz":-180,"elapsed":408,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"35b90b17-9378-4250-83fb-fb9b526b29b4"},"source":["question = squad[\"validation\"][0][\"question\"] \n","context = squad[\"validation\"][0][\"context\"] \n","print(\"Question:\") \n","print(question) \n","print(\"Context:\") \n","print(context) "],"execution_count":18,"outputs":[{"output_type":"stream","text":["Question:\n","In what country is Normandy located?\n","Context:\n","The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EpjiJ2cakjk7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625335807444,"user_tz":-180,"elapsed":692,"user":{"displayName":"meysam asgari chenaghlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN-uRJ5KciT9X_sZpZ4pOpEANlj5GCtXuY2ecq=s64","userId":"13491140841572947804"}},"outputId":"4581aef2-6bfd-4dc7-9656-2a1fe3054e53"},"source":["qa_model(question=question, context=context) "],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'France', 'end': 165, 'score': 0.9889379143714905, 'start': 159}"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"m9FPNkxwkoca"},"source":[""],"execution_count":null,"outputs":[]}]}